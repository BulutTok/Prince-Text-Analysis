---
output:
  word_document: default
  html_document: default
  pdf_document: default
---



```{r}
#Task 1 
installed.packages('tidytext')
install.packages("gridExtra")

library(tidyverse)
library(tidytext) #text mining
library(gridExtra) #viewing multiple plots together
```


```{r}
#Task 2 
prince <- read_csv('prince_raw_data.csv')
```
```{r}
#Task 3 
names(prince)
```

```{r}
#Task 4 
prince <- prince %>%
  select(lyrics=text,song,year,album,peak,US.Pop,US.R.B)
```

```{r}
#Task 5 
prince <- prince %>%
 mutate(decade =
   ifelse(prince$year %in% 1978:1979, "1970s",
   ifelse(prince$year %in% 1980:1989, "1980s",
   ifelse(prince$year %in% 1990:1999, "1990s",
   ifelse(prince$year %in% 2000:2009, "2000s",
  ifelse(prince$year %in% 2010:2015, "2010s",
                                            "NA"))))))

```

```{r}
prince <- prince %>%
  mutate (chart_level =
  ifelse(prince$peak %in% 1:10, "Top 10",
  ifelse(prince$peak %in% 11:100, "Top 100", "Uncharted")))
```

```{r}
#Task 6 
names(prince)

#There are 6 variables 
```
```{r}
#Task 7 
fix.contractions <- function(doc) {

doc <- gsub("won't", "will not", doc)
doc <- gsub("can't", "can not", doc)
doc <- gsub("n't", " not", doc)
doc <- gsub("'ll", " will", doc)
doc <- gsub("'re", " are", doc)
doc <- gsub("'ve", " have", doc)
doc <- gsub("'m", " am", doc)
doc <- gsub("'d", " would", doc)
doc <- gsub("'s", "", doc)
return(doc)
}

prince$lyrics <- sapply(prince$lyrics, fix.contractions)
```



```{r}
tidy_prince <- prince %>%
  unnest_tokens("word", lyrics)

```


```{r}
#Task 8 

undesirable_words <- c("prince","chorus","repeat","lyrics","theres",
"bridge", "fe0f", "yeah", "baby", "alright", "wanna", "gonna", "chorus",
"verse", "whoa","gotta", "make", "miscellaneous", "2","4","ooh","uurh",
"pheromone", "poompoom", "3121", "matic"," ai "," ca "," la ","hey"," na",
" da "," uh "," tin "," ll", "transcription", "repeats")

tidy_prince <-tidy_prince %>%
  anti_join(stop_words) %>%
  filter(!word %in% undesirable_words) %>%
  filter(nchar(word) > 3) 
  
head(tidy_prince)
```
```{r}
#Task 9 
popular_words <- prince %>%
  unnest_tokens("word", lyrics) %>%
  anti_join(stop_words)%>%
  filter(!word %in% undesirable_words) %>%
  filter(nchar(word) > 3) %>%
  group_by(song) %>%
  count(song, word, sort = TRUE)     #Counting the words for each song

head(popular_words)

```




```{r}
#Task 9 
my_colors <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", "#D55E00", "#D65E00")


tidy_prince %>%
  count(word, sort = TRUE) %>%                #get the n top words from the tidied, clean, filtered dataset using count() and top_n() 
  top_n(10) %>%
  ungroup() %>%                           
  mutate(word = reorder(word, n)) %>%         #sort words according to the count using reorder()and reassign the ordered value to word using mutate()
    ggplot() +
    geom_col(aes(word, n), fill = my_colors[5]) +
    xlab("") + 
    ylab("Word Count") +
    ggtitle("Most Frequently Used Words in Prince Lyrics") +
    coord_flip()

```
```{r}
#Task 10 
popular_tfidf_words <- prince %>%
  unnest_tokens("word", lyrics) %>%
  anti_join(stop_words)%>%  
  filter(!word %in% undesirable_words) %>%
  filter(nchar(word) > 3) %>%
  group_by(song) %>%
  count(song, word, sort = TRUE) %>%     
  bind_tf_idf(word,song, n)              


head(popular_tfidf_words)
```


```{r}
#Task 10 

popular_tfidf_words <- prince %>%
  unnest_tokens("word", lyrics) %>%
  anti_join(stop_words)%>%  
  filter(!word %in% undesirable_words) %>%
  filter(nchar(word) > 3) %>%
  group_by(song) %>%
  count(song, word, sort = TRUE) %>%     #Counting the words for each song
  bind_tf_idf(word,song, n)              #examine the most important words per song with the bind_tf_idf() function. 


head(popular_tfidf_words)
```

```{r}
#Task 11
list <- c("push it up", "shake","party up")
top_popular_tfidf_words <- popular_tfidf_words %>%
  filter(song %in% list) %>%  
  arrange(desc(tf_idf)) %>%                              
  mutate(word=reorder_within(word,tf_idf,song))%>%     
  top_n(10) %>%                                                 
  ggplot(aes(tf_idf, word, fill = song) )+
    geom_col(show.legend = NULL) +
    ylab(NULL) + 
    xlab("TF-IDF") +
    ggtitle("Important Words using TF-IDF by Song") +
    scale_y_reordered() +
    facet_wrap(~song, ncol = 2, scales = "free") 
 
top_popular_tfidf_words
```
```{r}
#Task 12 

#my_colors <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", "#D55E00", "#D65E00")


#popular_words_decade%>%
  #count(word, sort = TRUE) %>%                #get the n top words from the tidied, clean, filtered dataset using count() and top_n() 
  #top_n(10) %>%
  #ungroup() %>%                           
 # mutate(word = reorder(word, n)) %>%         #sort words according to the count using reorder()and reassign the ordered value to word using mutate()
  #  ggplot() +
  #  geom_col(aes(word, decade), fill = my_colors[5]) +
  #  xlab("") + 
  #  ylab("Word Count") +
   # ggtitle("Most Frequently Used Words in Prince Lyrics") +
   # coord_flip()
```


```{r}
popular_words_decade <- prince %>%
  unnest_tokens("word", lyrics) %>%
  anti_join(stop_words)%>%
  filter(!word %in% undesirable_words) %>%
  filter(nchar(word) > 3) %>%
  group_by(decade) %>%
  count(song, word, sort = TRUE)     #Counting the words for each song

head(popular_words_decade)
```




```{r}
popular_words <- prince %>%
  unnest_tokens("word", lyrics) %>%
  anti_join(stop_words) %>%
  filter(!word %in% undesirable_words) %>%
  filter(nchar(word) > 3) %>%
  mutate(decade = cut(year, breaks = seq(1950, 2020, by = 10), labels = paste(seq(1950, 2010, by = 10), "-", seq(1959, 2019, by = 10)))) %>%
  group_by(decade) %>%
  count(word, sort = TRUE) %>%
  ungroup()

# To visualize the most popular words per decade
library(ggplot2)
popular_words %>%
  group_by(decade) %>%
  top_n(10) %>%
  ggplot(aes(x = reorder_within(word, n, decade), y = n, fill = decade)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~decade, scales = "free") +
  coord_flip() +
  labs(x = "Word", y = "Frequency", title = "Top 10 Most Popular Words per Decade")

```

```{r}


# Group by decade and word
decade_words <- popular_words %>%
  group_by(decade, word) %>%
  summarise(word_count = sum(n)) %>%
  ungroup()

# Get the top 10 words per decade
top_words_per_decade <- decade_words %>%
  group_by(decade) %>%
  top_n(10, word_count) %>%
  arrange(decade, desc(word_count))

# Plot the most frequently used words per decade
library(ggplot2)
ggplot(top_words_per_decade, aes(x = reorder(word, word_count), y = word_count, fill = decade)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ decade, scales = "free") +
  scale_fill_manual(values = my_colors) +
  coord_flip() +
  labs(x = "Word", y = "Word Count", title = "Most Frequently Used Words in Prince's Lyrics per Decade")

```
